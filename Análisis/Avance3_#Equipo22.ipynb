{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Avance 3. Baseline\n",
    "\n",
    "# Respuestas a las preguntas\n",
    "1. **¿Qué algoritmo se puede utilizar como baseline para predecir las variables objetivo?**\n",
    "   \n",
    "En nuestro caso, hemos implementado dos modelos basados en los servicios de Azure. El primero se encarga de la clasificación de documentos, mientras que el segundo se dedica a la identificación y extracción de información. Además, ambos algoritmos pueden potenciarse mediante la integración de los modelos preentrenados de Azure Form Recognizer, que aplican técnicas avanzadas de deep learning y transfer learning para optimizar la clasificación y extracción de datos.\n",
    "\n",
    "2. **¿Se puede determinar la importancia de las características para el modelo generado?**\n",
    "\n",
    "Si para este caso realizamos el etiquetado de los documentos a clasificar, los cuales tienen caracteristicas notorias como ciertas imagenes, longitud de documento, secciones las cuales son interpretadas por el modeo de clasificación.\n",
    "\n",
    "Se tienen las siguientes cantidades de datos:\n",
    "\n",
    "| Mes        | Datos de entrenamiento | Datos de prueba | Total |\n",
    "|------------|-------------------------|-----------------|-------|\n",
    "| Diciembre  | 7                       | 3               | 10    |\n",
    "| Noviembre  | 5                       | 2               | 7     |\n",
    "| Octubre    | 9                       | 4               | 13    |\n",
    "| **Total**  | 21                      | 9               | 30    |\n",
    "\n",
    "Dada la distribución de los actas como primer paso se van a clasificar 21 documentos de la siguiente manera:\n",
    "\n",
    "| Tipo de Acta               | Cantidad |\n",
    "|----------------------------|----------|\n",
    "| FNA Ahorro                 | 12       |\n",
    "| Fondo nacional del ahorro  | 9        |\n",
    "\n",
    "Se muestra la clasificación mediante etiquetado a los documentos del conjunto de pruebas:\n",
    "![Etiquetado](evidencias_avance_3/etiquetado.png \"Etiquetado\")\n",
    "\n",
    "Ejecutamos el entrenamiento para generar nuestro modelo:\n",
    "\n",
    "![Entrenamiento](evidencias_avance_3/entrenamiento.png \"Entrenamiento\")\n",
    "\n",
    "Ya teniendo nuestro modelo entrenado con los 21 documentos, vamos a evaluar el modelo con los 9 documentos:\n",
    "\n",
    "![Evaluación](evidencias_avance_3/evaluacion.png \"Evaluación\")\n",
    "\n",
    "A lo cual obtenemos los siguientes resultados:\n",
    "\n",
    "![Resultados](evidencias_avance_3/resultados.png \"Resultados\")\n",
    "\n",
    "3. **¿El modelo está sub/sobreajustando los datos de entrenamiento?**\n",
    "\n",
    "Se observa que el modelo clasifica correctamente todas las instancias en el conjunto evaluado. Esto indica que el modelo no presenta subajuste (underfitting), ya que está capturando perfectamente los patrones de los datos evaluados.\n",
    "\n",
    "Sin embargo, es importante considerar lo siguiente:\n",
    "\n",
    "**Posible Sobreajuste (Overfitting):**\n",
    "Aunque los resultados son perfectos, si el conjunto de prueba es muy pequeño (en este caso, 9 documentos) o no es suficientemente diverso (por ejemplo, contiene únicamente ejemplos de la clase positiva), estos resultados podrían ser indicativos de un sobreajuste. Es decir, el modelo podría estar memorizando los datos de entrenamiento en lugar de aprender patrones generalizables a nuevos datos.\n",
    "\n",
    "**Recomendación:**\n",
    "Se recomienda evaluar el modelo con un conjunto de datos más amplio y representativo, que incluya ejemplos de ambas clases (positiva y negativa), para poder confirmar si el desempeño perfecto se mantiene en condiciones más realistas y verificar que el modelo generaliza correctamente.\n",
    "\n",
    "4. **¿Cuál es la métrica adecuada para este problema de negocio?**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "F1 Score: 1.0\n",
      "AUC-ROC: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score\n",
    "\n",
    "# Supongamos que \"1\" representa una clasificación fna_ahorro y fondo_nacional_ahorro .\n",
    "y_true = [1, 1, 1, 1, 1, 0, 0, 1, 1]  # Etiquetas reales\n",
    "y_pred = [1, 1, 1, 1, 1, 0, 0, 1, 1]  # Etiquetas predichas\n",
    "\n",
    "# Calcular Accuracy y F1-score\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "# Para calcular AUC-ROC se requieren probabilidades predichas\n",
    "y_scores = [0.792, 0.773, 0.92, 0.9, 0.96, 0.416, 0.674, 0.783, 0.832]\n",
    "\n",
    "# Calcular AUC-ROC\n",
    "try:\n",
    "    auc = roc_auc_score(y_true, y_scores)\n",
    "except ValueError as e:\n",
    "    auc = None\n",
    "    print(\"No se pudo calcular AUC-ROC:\", e)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"AUC-ROC:\", auc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estos resultados indican que, en el conjunto de prueba evaluado, el modelo ha logrado clasificar correctamente todas las instancias. En detalle:\n",
    "\n",
    "- **Accuracy** de 1.0: Significa que el modelo ha clasificado correctamente el 100% de los documentos.\n",
    "\n",
    "- **F1 Score** de 1.0: Refleja que tanto la precisión como el recall son perfectos, es decir, no hubo ni falsos positivos ni falsos negativos.\n",
    "\n",
    "- **AUC-ROC** de 1.0: Sugiere que el modelo tiene una capacidad ideal para diferenciar entre clases.\n",
    "\n",
    "Por lo cual estas 3 metricas nos permiten entender desde puntos de vistas distintos y mostrar que el modelo es muy bueno y cada uno complementa el entendimiento del mismo.\n",
    "\n",
    "5. **¿Cuál debería ser el desempeño mínimo a obtener?**\n",
    "\n",
    "Para el negocio, es fundamental que el sistema de clasificación alcance una precisión del 100% y un AUC-ROC cercano a 1.0. Esto garantiza que el modelo discrimine de manera óptima entre los documentos relevantes y los que no lo son, asegurando que únicamente aquellos correctamente clasificados sean procesados por el modelo de extracción. De esta forma, se mantiene la consistencia de los datos y se optimizan los recursos en etapas posteriores del procesamiento."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "842ea6a284c0768e4a2219e39e4f6378de4471fb64c90387f3eacce26856343b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
